

<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="description" content="Ran&#39;s home page">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Xin TAN （谭鑫）</title>
</head>



<body>



<div style="margin-top:25px">

 <script src="/assets/js/scale.fix.js"></script>


<div id="toptitle">					
<h1>Xin TAN &nbsp; (谭&nbsp;&nbsp;鑫)<a name="top"></a></h1>
</div>




<table>
		<tr>
			<td width="80%"> 
				<p>
					<strong>青年研究员（“双百人才计划”紫江青年学者），院长助理</strong><br>
					华东师范大学计算机科学与技术学院<br><br>

					<strong>Research Professor (Zijiang Young Scholar), Assistant to the Dean of</strong><br> 
					School of Computer Science and Technology,<br>
					East China Normal University (ECNU), Shanghai, China<br>
					<!--Team: <a href="https://dmcv-ecnu.github.io/">ECNU Digital Media and Computer Vision Laboratory (DMCV)</a><br>
					&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp<a href="https://dmcv.sjtu.edu.cn/people/"> SJTU Digital Media and Computer Vision Laboratory (DMCV)</a><br>-->
					<br>Email: <!--<del>tanxin2017 AT sjtu.edu.cn</del>&nbsp;&nbsp;--> xtan AT cs.ecnu.edu.cn<br>
					Office: 615B, Science Building, 3663 Zhongshan North Road<br>
					<a href="https://scholar.google.com/citations?hl=zh-CN&user=UY4NCdcAAAAJ&view_op=list_works" target="_blank">[Google Scholar]</u></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					<a href="https://faculty.ecnu.edu.cn/_s16/tx2/main.psp" target="_blank">[Official Homepage]</u></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					<!--<a href="" target="_blank">[CV]</u></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					<a href="" target="_blank">[Github]</u></a><br>-->
				</p>
			</td>
			<td>
				<img src="./xin2023.jpg" border="0" width="160">
			</td>
		</tr>
</table>


<font color="red"><strong><em>News</em></strong></font>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>News Section with Scrollbar</title>
    <style>
        .news-container {
            width: 100%;
            max-width: 1500px; 
            height: 500px; 
            overflow-y: auto;
            border: 0.1px solid #ccc;
            padding: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.01);
            border-radius: 8px;
            box-sizing: border-box;
            background-color: rgba(255, 255, 255, 0.1); 
        }
        .news-item {
            margin-bottom: 10px;
        }
        .news-item:last-child {
            margin-bottom: 0;
        }
    </style>
</head>
<body>
    <div class="news-container">
		<div class="news-item"><strong>[2025-02-01]</strong> Two papers are accepted to CVPR 2025.</div>
		<div class="news-item"><strong>[2025-02-01]</strong> I am promoted to Research Professor (Zijiang Young Scholar), equivalent to Pre-tenure Professor.</div>
		<div class="news-item"><strong>[2025-01-25]</strong> One paper is accepted to TITS.</div>
		<div class="news-item"><strong>[2025-01-20]</strong> I am selected into Young Elite Scientists Sponsorship Program by CAST, nominated by China Graphics Society (CGS)  （第十届中国科协青年人才托举工程） .</div>
		<div class="news-item"><strong>[2024-12-10]</strong> Two papers are accepted to AAAI 2025.</div>
		<div class="news-item"><strong>[2024-11-22]</strong> I won the 2024 CSIG Excellent Doctoral Dissertation （2024年度中国图象图形学学会博士学位论文激励计划）.</div>
		<div class="news-item"><strong>[2024-11-21]</strong> One paper is accepted to TMM.</div>
		<div class="news-item"><strong>[2024-10-26]</strong> I won the 2023 CCF-Tencent Rhino-Bird Fund Excellent Project （2023年度CCF-腾讯犀牛鸟基金优秀项目） .</div>
        <div class="news-item"><strong>[2024-09-28]</strong> One paper is accepted to NeurIPS！</div>
		<div class="news-item"><strong>[2024-08-22]</strong> One paper is accepted to IEEE TPAMI！</div>
        <div class="news-item"><strong>[2024-06-12]</strong> I have one paper (PIG) accepted to IEEE TIP. This is my third paper for night-time scene segmentation accepted by TIP.</div>
        <div class="news-item"><strong>[2024-05-16]</strong> One paper is accepted to ACL 2024!</div>
        <div class="news-item"><strong>[2024-04-15]</strong> I am invited to serve as the Associate Editor (AE) of <a href="https://www.sciencedirect.com/journal/pattern-recognition">Pattern Recognition (PR)</a>.</div>
        <div class="news-item"><strong>[2024-02-27]</strong> Four papers are accepted to CVPR 2024!</div>
        <div class="news-item"><strong>[2024-02-21]</strong> One paper is accepted to IEEE TIP! This is the second paper accepted by IEEE TIP this month.</div>
        <div class="news-item"><strong>[2024-02-07]</strong> One paper is accepted to IEEE TIP!</div>
        <div class="news-item"><strong>[2024-01-17]</strong> One paper is accepted to ICLR 2024 spotlight (5% acceptance rate)!</div>
        <div class="news-item"><strong>[2024-01-12]</strong> The course Digital Logic Circuit I teach is awarded as the most popular course for students.</div>
        <div class="news-item"><strong>[2024-01-01]</strong> One paper is accepted to IEEE Transactions on Industrial Informatics (TII).</div>
        <div class="news-item"><strong>[2023-12-09]</strong> Four papers are accepted to AAAI 2024!</div>
        <div class="news-item"><strong>[2023-12-08]</strong> I am granted by the Chenguang Program of Shanghai Education Development Foundation and Shanghai Municipal Education Commission （上海市晨光计划）.</div>
        <div class="news-item"><strong>[2023-12-02]</strong> I share a talk at the forum of 2023 Chinese Conference on Biometric Recognition (CCBR 2023).</div>
        <div class="news-item"><strong>[2023-12-01]</strong> I share a talk at China University of Mining and Technology.</div>
        <div class="news-item"><strong>[2023-11-05]</strong> I am invited to serve as the Associate Editor (AE) of <a href="https://www.springer.com/journal/371">The Visual Computer</a>.</div>
        <div class="news-item"><strong>[2023-10-26]</strong> One paper is accepted to Computational Visual Media.</div>
        <div class="news-item"><strong>[2023-09-28]</strong> One paper is accepted to Journal of Computer-Aided Design & Computer Graphics (in Chinese).</div>
        <div class="news-item"><strong>[2023-09-23]</strong> One paper is accepted to IEEE TPAMI!</div>
        <div class="news-item"><strong>[2023-09-18]</strong> Our paper Mirror Detection with the Visual Chirality Cue becomes an ESI Highly Cited paper.</div>
        <div class="news-item"><strong>[2023-08-24]</strong> I am granted by the National Natural Science Foundation of China （国家自然科学基金青年基金）.</div>
        <div class="news-item"><strong>[2023-07-31]</strong> I am granted by the CCF-Tencent Rhino-Bird Young Faculty Open Research Fund （CCF-腾讯犀牛鸟基金）.</div>
        <div class="news-item"><strong>[2023-07-25]</strong> One paper is accepted to ACM MM 2023.</div>
        <div class="news-item"><strong>[2023-07-18]</strong> One paper is accepted to ICCV 2023.</div>
        <div class="news-item"><strong>[2023-05-27]</strong> I am granted by the Natural Science Foundation of Chongqing, China （重庆市自然基金面上项目）.</div>
        <div class="news-item"><strong>[2023-05-17]</strong> I share a talk about <a href="http://www.cjig.cn/jig/ch/reader/view_abstract.aspx?file_no=230004&flag=1">3D point cloud</a> at the forum of 2023 Chinese Congress on Image and Graphics (CCIG 2023).</div>
        <div class="news-item"><strong>[2023-04-05]</strong> I have one paper accepted to IEEE TIP. This is another important paper for night-time scene segmentation.</div>
        <div class="news-item"><strong>[2023-03-31]</strong> I am granted by the 2023 open project from Shanghai Key Laboratory of Computer Software Testing & Evaluating （2023年上海市计算机软件评测重点实验室开放课题）.</div>
        <div class="news-item"><strong>[2023-02-28]</strong> I have four papers accepted to CVPR 2023.</div>
        <div class="news-item"><strong>[2023-02-10]</strong> I am granted by the Shanghai Sailing Program （上海市青年科技英才扬帆计划资助项目）.</div>
        <div class="news-item"><strong>[2022-08-20]</strong> I share a talk about autonomous driving at the forum of 2022 Chinese Congress on Image and Graphics (CCIG 2022).</div>
        <div class="news-item"><strong>[2022-08-11]</strong> I am awarded the Second Prize for Progress in Science and Technology by the China Association For GIS.</div>
        <div class="news-item"><strong>[2022-07-12]</strong> I join East China Normal University as an Associate Research Professor.</div>
        <div class="news-item"><strong>[2022-07-10]</strong> One paper is accepted to ECCV 2022.</div>
    </div>

</body>

<font color="red"><strong><em>Opening positions</em><br/></strong></font> 
I am looking for self-motivated master and undergraduate students to work with me at ECNU! 
If you are interested in computer vision and want to join us, please send me your CV via email. <br/>
团队招收有自我驱动力的博士生、硕士生和本科生。如果你对团队在华东师范大学学习机会感兴趣，可以邮件联系我。<br/>

<del><font color="red"><strong><em>[2024-08-09] 团队开始招收2025年通过9月推免生考核入学的推免硕士生/直博生，欢迎感兴趣的考生与我联系。</em><br/></strong></font></del>
<del><font color="red"><strong><em>[2024-08-01] 团队有多个2025年秋入学的博士名额（合作导师：马利庄教授、谢源教授），可以招收直博生或者普博生，欢迎咨询。</em><br/></strong></font></del>
<del><font color="red"><strong><em>[2024-05-01] 团队开始招收2025年通过夏令营入学的推免硕士生，欢迎感兴趣的考生与我联系。</em><br/></strong></font> </del>
<!--<img src="./xin2022.jpg" width="180" height="236"  alt="tanxin" style='position:absolute;left:589;top:12'/>-->
<hr />

<!--<font color="red"><strong><em>Call for papers</em><br/></strong></font> 
We are organizing a special issue, The Latest Deep Learning Architectures for Artificial Intelligence Applications, on <strong>CMC-Computers, Materials & Continua (SCI, JCR Q3, IF: 3.1)</strong>.
Welcome submissions! The submission due time is <strong>31 Dec. 2024</strong>. The details can be found at <a href="https://www.techscience.com/cmc/special_detail/deep-learning-architectures"><font color="red"><strong>CFP</strong></font> </a>.-->


<hr />

<h2>Biography &nbsp;   </h2>
<p>
	Dr. Xin Tan is the Research Professor (Zijiang Young Scholar) with School of Computer Science and Technology, East China Normal University, China. 
	Before that, he was the Associate Research Professor at ECNU.
	He is a member of Digital Media and Computer Vision Laboratory, the SJTU-ECNU joint lab led by <a href="https://dmcv.sjtu.edu.cn/people/">Prof. Lizhuang Ma</a>. 
	He received his dual Ph.D. degree from Shanghai Jiao Tong University, China and City University of Hong Kong, China in 2022. His Ph.D. advisor is <a href="http://dmcv.sjtu.edu.cn/people/">Prof. Lizhuang Ma</a> (SJTU), and <a href="http://www.cs.cityu.edu.hk/~rynson/">Prof. Rynson Lau</a> (CityU). 
	He received his B.Eng degree and B.BM degree from Chongqing University, China, in 2017.
	He also closely works with <a href="https://faculty.ecnu.edu.cn/_s16/xy2_11342/main.psp">Prof. Yuan Xie</a>. 
	His research interests include computer vision and pattern recognition, especially the scene understanding and reconstruction for Embodied AI.

	
</p>
<hr />

<!--<h2><font color="blue">Education Experience</font></h2>

<ul>
<li><p>2019 - Present: Joint Ph.D Scheme, supervised by Prof. <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson Lau</a>, Department of Computer Science, City University of Hong Kong.</p></li>
<li><p>2017 - Present:  Ph.D, supervised by Distinguished Prof. <a href="http://dmcv.sjtu.edu.cn/people/">Lizhuang Ma</a>, Department of Computer Science and Engineering, Shanghai Jiao Tong University.</p></li>
<li><p>2014 - 2017: Bachelor of Management, School of Economics and Business Administration, Chongqing University.</p></li>
<li><p>2013 - 2017: Bachelor of Engineering, School of Automation, Chongqing University. Advisor: Prof. <a href="http://accu.cqu.edu.cn/info/1057/3032.htm">Hongpeng Yin</a></p></li>
</ul>-->

<h2>Research Fundings &nbsp;   </h2>
<p>
	I appreciate the organizations listed below for the sponsorship to my research.<br/>
	
	<img src="./nsfc.png" border="0" width="160">
	<img src="./cast.jpg" border="0" width="160">
	<img src="./stcsm.png" border="0" width="160">
	<img src="./cqkjj.png" border="0" width="160">
	<img src="./sstl.png" border="0" height= "33" width="160">
	<img src="./youtu.png" border="0" height= "40" width="160">
	<img src="./ccf-tencent.png" border="0" height= "40" width="160">
	<br/>
	

<ul>
	
	<li><strong>国家自然科学基金青年基金</strong>，62302167，2024.01-2026.12，国家自然科学基金委员会，<strong>项目负责人</strong></li><br/>
	
	<li><strong>国家自然科学基金联合基金重点项目</strong>，U23A20343，2024.01-2027.12，国家自然科学基金委员会，<strong>课题负责人</strong></li><br/>

	<li><strong>第十届中国科协青年人才托举工程</strong>， 2024-2026，中国科协，<strong>项目负责人</strong></li><br/>
	
	<li><strong>上海市青年科技英才扬帆计划资助项目</strong>，23YF1410500，2023.04-2026.03，上海市科学技术委员会，<strong>项目负责人</strong></li><br/>
	
	<li><strong>上海市晨光计划（A类）</strong>，23CGA34，2024.01-2025.12，上海市教育发展基金会/上海市教育委员会，<strong>项目负责人</strong></li><br/>
	
	<li><strong>重庆市自然基金面上项目</strong>，CSTB2023NSCQ-MSX0137，2023.07-2026.06，重庆市科技局，<strong>项目负责人</strong></li><br/>
	

    <style>hr.dashed {border: none;border-top: 1px dashed black;color: #333;background-color: #fff;height: 1px;}</style>
<hr class="dashed">

    <li><strong>CCF-腾讯犀牛鸟基金</strong>，CCF-Tencent RAGR20230121，2023.10-2024.9，CCF-腾讯，<strong>项目负责人</strong> <strong><em><font color="red">（优秀结题项目）</font></em></strong></li><br/>
	
    <li><strong>腾讯优图实验室校企联合项目</strong>，2023.12-2024.11，<strong>项目负责人</strong></li><br/>
	
    <li><strong>上海市计算机软件评测重点实验室开放课题</strong>，SSTL2023_01，2023.4-2023.12，上海市计算机软件评测重点实验室，<strong>项目负责人</strong></li><br/>

    <li><strong>腾讯优图实验室校企联合项目</strong>，2022.12-2023.11，<strong>项目负责人</strong></li><br/>

    <li><strong>腾讯优图实验室校企联合项目</strong>，2022.7-2022.12，<strong>项目负责人</strong></li><br/>

	
	
</p>
<hr />





<h2>Preprint &nbsp;   </h2>

<ul>

<li><p><font color="[0.1,0.6,0.99]"><strong>FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents</strong></font> <br />
<strong>Xin Tan</strong>, Yuzhou Ji, He Zhu, Yuan Xie<br />
<em>Preprint</em>, 2025<br/>
[<a href="https://arxiv.org/abs/2504.08581"> PDF </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>IDMR: Towards Instance-Driven Precise Visual Correspondence in Multimodal Retrieval</strong></font> <br />
Bangwei Liu, Yicheng Bao, Shaohui Lin, Xuhong Wang, <strong>Xin Tan#</strong>, Yingchun Wang, Yuan Xie, Chaochao Lu (# corresponding author)<br />
<em>Preprint</em>, 2025<br/>
[<a href="https://arxiv.org/abs/2504.00954">PDF</a>]
[<a href="https://github.com/BwLiu01/IDMR">Code</a>]
[<a href="https://huggingface.co/spaces/lbw18601752667/IDMR-demo">Huggingface</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Efficient Multimodal Large Language Models: A Survey</strong></font> <br />
Yizhang Jin, Jian Li, Yexin Liu, Tianjun Gu, Kai Wu, Zhengkai Jiang, Muyang He, Bo Zhao, <strong>Xin Tan</strong>, Zhenye Gan, Yabiao Wang, Chengjie Wang, Lizhuang Ma<br />
<em>Preprint</em>, 2024<br/>
[<a href="https://arxiv.org/abs/2405.10739"> PDF </a>]
</p></li>

	

<li><p><font color="[0.1,0.6,0.99]"><strong>Gradient Projection For Parameter-Efficient Continual Learning</strong></font> <br />
Jingyang Qiao, Zhizhong Zhang, <strong>Xin Tan</strong>, Yanyun Qu, Wensheng Zhang, Yuan Xie<br />
<em>Preprint</em>, 2024<br/>
<strong><em><font color="red">(The extented version of ICLR 2024)</font></em></strong><br/> 
[<a href="https://arxiv.org/abs/2405.13383"> PDF </a>]
</p></li>	

<li><p><font color="[0.1,0.6,0.99]"><strong>Generalized Category Discovery in Semantic Segmentation</strong></font> <br />
Zhengyuan Peng, Qijian Tian, Jianqing Xu, Yizhang Jin, Xuequan Lu, <strong>Xin Tan#</strong>, Yuan Xie, Lizhuang Ma<br />
<em>Preprint</em>, 2023<br/>
[<a href="https://arxiv.org/abs/2311.11525"> PDF </a>]
</p></li>
	
</ul>

<h2>Publications</h2>
<ul>


<font color="red"><strong><em>2025</em><br/></strong></font> 

CVPR*2, AAAI*2, TMM*1, TITS*1, TNNLS*1, CVM*1, PR*1

<li><p><font color="[0.1,0.6,0.99]"><strong>MMoFusion: Multi-modal Co-Speech Motion Generation with Diffusion Model</strong></font> <br />
	Sen Wanga, Jiangning Zhang, <strong>Xin Tan#</strong>, Zhifeng Xie, Chengjie Wang, Lizhuang Ma (# corresponding author)<br />
	<em>Pattern Recognition</em>, 2025 <br/> 
	[<a href="">PDF (coming soon)  </a>]
	[<a href="">Code (coming soon)  </a>]
	</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>MOS: Modeling Object-Scene Associations in Generalized Category Discovery</strong></font> <br />
	Zhengyuan Peng, Jinpeng Ma, Zhimin Sun, Ran Yi, Haichuan Song, <strong>Xin Tan#</strong>, Lizhuang Ma(# corresponding author)<br />
	<em>Proc. IEEE CVPR</em>, 2025 <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
	[<a href="https://arxiv.org/abs/2503.12035">PDF </a>]
	[<a href="https://github.com/JethroPeng/MOS">Code </a>]
	</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>One for More: Conditinual Diffusion Model for Anomaly Detection</strong></font> <br />
	Xiaofan Li, <strong>Xin Tan</strong>, Zhuo Chen, Zhizhong Zhang, Ruixin Zhang, Rizen Guo, Guannan Jiang, Yulong Chen, Yanyun Qu, Lizhuang Ma, Yuan Xie<br />
	<em>Proc. IEEE CVPR</em>, 2025 <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
	[<a href="https://arxiv.org/abs/2502.19848">PDF </a>]
	[<a href="">Code (coming soon) </a>]
	</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>GEOcc: Geometrically Enhanced 3D Occupancy Network with Implicit-Explicit Depth Fusion and Contextual Self-Supervision</strong></font> <br />
	<strong>Xin Tan</strong>, Wenbin Wu, Zhiwei Zhang, Chaojie Fan, Yong Peng, Zhizhong Zhang, Yuan Xie, Lizhuang Ma<br />
	<em>IEEE Transactions on Intelligent Transportation Systems (TITS)</em>, 2025<br/>
	[<a href="https://arxiv.org/pdf/2405.10591"> PDF </a>]
	[<a href="https://github.com/world-executed/GEOcc">Code </a>]
	</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Bias to Balance: New-Knowledge-Preferred Few-Shot Class-Incremental Learning via Transition Calibration</strong></font> <br />
	Hongquan Zhang , Zhizhong Zhang , <strong>Xin Tan</strong>, Yanyun Qu, Yuan Xie<br />
	<em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</em>, 2025<br/>
	[<a href="https://ieeexplore.ieee.org/document/10970073/authors#authors"> PDF </a>]
	</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>DepthFisheye: Efficient Fine-Tuning of Depth Estimation Models for Fisheye Cameras</strong></font> <br />
	<em>Conference on Computational Visual Media (CVM)</em>, 2025<strong></strong><br/>
	Wenbin Wu, Zhiwei Zhang, <strong>Xin Tan</strong>,  Zhizhong Zhang, Lizhuang Ma<br />
	[<a href=""> PDF (coming soon)</a>]
	</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>DrivingForward: Feed-forward 3D Gaussian Splatting for Driving Scene Reconstruction from Flexible Surround-view Input</strong></font> <br />
	Qijian Tian, <strong>Xin Tan#</strong>, Yuan Xie, Lizhuang Ma (# corresponding author)<br />
	<em>AAAI</em>, 2025<strong><em><font color="red">(CCF-A)</font></em></strong><br/>
	[<a href="https://arxiv.org/abs/2409.12753"> PDF </a>]
	[<a href="https://fangzhou2000.github.io/projects/drivingforward/">Project Page</a>]
	[<a href="https://mp.weixin.qq.com/s/u7TK-PkUqUg5347DHtyQQQ">中文简介</a>]
	</p></li>	


<li><p><font color="[0.1,0.6,0.99]"><strong>FastLGS: Speeding up Language Embedded Gaussians with Feature Grid Mapping</strong></font> <br />
Yuzhou Ji, He Zhu, Junshu Tang, Wuyi Liu, Zhizhong Zhang, <strong>Xin Tan#</strong>, Yuan Xie  (# corresponding author)<br />
<strong><em><font color="red">(YZ. J. and H. Z. are the fourth-year undergraduate students.)</font></em></strong> <br/>
<em>AAAI</em>, 2025<strong><em><font color="red">(CCF-A)</font></em></strong><br/>
[<a href="https://arxiv.org/abs/2406.01916"> PDF </a>]
[<a href="https://george-attano.github.io/FastLGS/">Project Page</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>WV-LUT: Wide Vision Lookup Tables for Real-Time Low-Light Image Enhancement</strong></font> <br />
Canlin Li, Haowen Su, <strong>Xin Tan#</strong>, Xiangfei Zhang, Lizhuang Ma (# corresponding author)<br />
	<em>IEEE Trans. on Multimedia (TMM)</em>, 2025<strong</strong><br/> 
	[<a href="https://ieeexplore.ieee.org/document/10855492">PDF</a>]
	[<a href="https://github.com/ssw219/WV-LUT">Code</a>]
	</p></li>

<font color="red"><strong><em>2024</em><br/></strong></font> 

TPAMI*1, CVPR*4, AAAI*4, TIP*3, ICLR*1, ACL*1, TII*1, CVM*1, NeurIPS*1



<li><p><font color="[0.1,0.6,0.99]"><strong>Harmonizing Visual Text Comprehension and Generation</strong></font> <br />
	Zhen Zhao, Jingqun Tang, Binghong Wu, Chunhui Lin, Shu Wei, Hao Liu, <strong>Xin Tan</strong>, Zhizhong Zhang, Can Huang, Yuan Xie<br />
	<em>NeurIPS</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
	[<a href="https://arxiv.org/abs/2407.16364">PDF</a>]
	[<a href="https://github.com/bytedance/TextHarmony">Code</a>]
	[<a href="https://mp.weixin.qq.com/s/PLF0dc1b-W5a59sK7XX0bA">中文简介</a>]
	</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Uni-to-Multi Modal Knowledge Distillation for Bidirectional LiDAR-Camera Semantic Segmentation</strong></font> <br />
	Tianfang Sun, Zhizhong Zhang, <strong>Xin Tan</strong>, Yong Peng, Yanyun Qu, Yuan Xie<br />
	<em>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
	[<a href="https://ieeexplore.ieee.org/document/10659158/">PDF</a>]
	</p></li>
	
<li><p><font color="[0.1,0.6,0.99]"><strong>PIG: Prompt Images Guidance for Night-Time Scene Parsing</strong></font> <br />
Zhifeng Xie, Rui Qiu, Sen Wang, <strong>Xin Tan#</strong>, Yuan Xie, Lizhuang Ma (# corresponding author)<br />
<em>IEEE Trans. on Image Processing (TIP)</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://ieeexplore.ieee.org/document/10570214">PDF </a>]
[<a href="https://github.com/qiurui4shu/PIG">Code </a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion</strong></font> <br />
Qibing Ren, Chang Gao, Jing Shao, Junchi Yan, <strong>Xin Tan</strong>, Wai Lam, Lizhuang Ma <br />
<em>ACL (Findings)</em>, 2024 <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://arxiv.org/abs/2403.07865"> PDF  </a>]
[<a href="https://github.com/renqibing/CodeAttack">Code</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection</strong></font> <br />
Xiaofan Li, Zhizhong Zhang, <strong>Xin Tan#</strong>, Yanyun Qu, Chengwei Chen, Yuan Xie, Lizhuang Ma (# corresponding author)<br />
<em>Proc. IEEE CVPR</em>, 2024 <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_PromptAD_Learning_Prompts_with_only_Normal_Samples_for_Few-Shot_Anomaly_CVPR_2024_paper.html"> PDF </a>]
[<a href="https://github.com/FuNz-0/PromptAD">Code</a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy Prediction</strong></font> <br />
Qihang Ma*, <strong>Xin Tan*</strong>, Yanyun Qu, Lizhuang Ma, Zhizhong Zhang, Yuan Xie (* joint first authors)<br />
<em>Proc. IEEE CVPR</em>, 2024 <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Ma_COTR_Compact_Occupancy_TRansformer_for_Vision-based_3D_Occupancy_Prediction_CVPR_2024_paper.html"> PDF </a>]
[<a href="https://github.com/NotACracker/COTR">Code</a>]
[<a href="https://mp.weixin.qq.com/s/0yLrY7Wa8g6uyHwECX37vA">中文简介</a>]
</p></li>



<li><p><font color="[0.1,0.6,0.99]"><strong>Multi-modal In-Context Learning Makes an Ego-evolving Scene Text Recognizer</strong></font> <br />
Zhen Zhao, Jingqun Tang, Chunhui Lin, Binghong Wu, Hao Liu, Zhizhong Zhang, <strong>Xin Tan</strong>, Can Huang, Yuan Xie<br />
<em>Proc. IEEE CVPR</em>, 2024 <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://arxiv.org/pdf/2311.13120"> PDF </a>]
[<a href="https://github.com/bytedance/E2STR">Code</a>]
[<a href="https://mp.weixin.qq.com/s/E8zMHQv6fSv09OXs9gybrQ">中文简介</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Building a Strong Pre-Training Baseline for Universal 3D Large-Scale Perception</strong></font> <br />
Haoming Chen, Zhizhong Zhang, Yanyun Qu, Ruixin Zhang, <strong>Xin Tan</strong>, Yuan Xie<br />
<em>Proc. IEEE CVPR</em>, 2024 <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Building_a_Strong_Pre-Training_Baseline_for_Universal_3D_Large-Scale_Perception_CVPR_2024_paper.html">PDF </a>]
[<a href="https://github.com/chenhaomingbob/CSC">Code</a>]
</p></li>




<li><p><font color="[0.1,0.6,0.99]"><strong>CSFwinformer: Cross-Space-Frequency Window Transformer for Mirror Detection</strong></font> <br />
Zhifeng Xie, Sen Wang, Qiucheng Yu, <strong>Xin Tan#</strong>, Yuan Xie (# corresponding author)<br />
<em>IEEE Trans. on Image Processing (TIP)</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://ieeexplore.ieee.org/document/10462920">PDF </a>]
[<a href="https://github.com/wangsen99/CSFwinformer">Code </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Image Understands Point Cloud: Weakly Supervised 3D Semantic Segmentation via Association Learning</strong></font> <br />
Tianfang Sun, Zhizhong Zhang, <strong>Xin Tan</strong>, Yanyun Qu, Yuan Xie<br />
<em>IEEE Trans. on Image Processing (TIP)</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://ieeexplore.ieee.org/document/10462911">PDF </a>]
[<a href="https://github.com/isunLt/IUPC">Code </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Prompt Gradient Projection for Continual Learning</strong></font> <br />
Jingyang Qiao, Zhizhong Zhang <strong>Xin Tan</strong>, Chengwei Chen, Yanyun Qu, Yong Peng, Yuan Xie<br />
<em>ICLR</em>, 2024 (spotlight)<strong><em><font color="red"> (5% acceptance rate)</font></em></strong><br/> 
[<a href="https://openreview.net/forum?id=EH2O3h7sBI">PDF </a>]
[<a href="https://github.com/JingyangQiao/prompt-gradient-projection">Code </a>]
[<a href="https://jingyangqiao.github.io/">Project page </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Glass Makes Blurs: Learning the Visual Blurriness for Glass Surface Detection</strong></font> <br />
Fulin Qi, <strong>Xin Tan#</strong>, Zhizhong Zhang, Mingang Chen, Yuan Xie, Lizhuang Ma (# corresponding author)<br />
<em>IEEE Transactions on Industrial Informatics</em>, 2024<strong><em><font color="red"> </font></em></strong><br/> 
<strong><em><font color="red">(ESI highly cited)</font></em></strong> <br/> 
[<a href="http://dx.doi.org/10.1109/TII.2024.3352232">PDF </a>]
[<a href="https://drive.google.com/file/d/1mjMMdBB016UJpl7wEaONmNvLlUW1hU2G/view?usp=sharing">Result Maps </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Beyond the Label Itself: Latent Labels Enhance Semi-supervised Point Cloud Panoptic Segmentation</strong></font> <br />
Yujun Chen*, <strong>Xin Tan*</strong>, Zhizhong Zhang, Yanyun Qu, Yuan Xie (* joint first authors)<br />
<em>Proc. AAAI</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/27887">PDF </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Learning Task-Aware Language-Image Representation for Class-Incremental Object Detection</strong></font> <br />
Hongquan Zhang, Bin-Bin Gao, Yi Zeng, Xudong Tian <strong>Xin Tan#</strong>, Zhizhong Zhang, Yanyun Qu, Jun Liu, Yuan Xie (# corresponding author)<br />
<em>Proc. AAAI</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28537">PDF </a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Domain-Hallucinated Updating for Multi-Domain Face Anti-spoofing</strong></font> <br />
Chengyang Hu, Ke-Yue Zhang, Taiping Yao, Shice Liu, Shouhong Ding, <strong>Xin Tan</strong>, Lizhuang Ma <br />
<em>Proc. AAAI</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/27992">PDF </a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Continuous Piecewise-Affine Based Motion Model for Image Animation</strong></font> <br />
Hexiang Wang, Fengqi Liu, Qianyu Zhou, Ran Yi, <strong>Xin Tan</strong>, Lizhuang Ma<br />
<em>Proc. AAAI</em>, 2024<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28351">PDF </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Leveraging Panoptic Prior for 3D Zero shot Semantic Understanding within Language Embedded Radiance Fields</strong></font> <br />
Yuzhou Ji, <strong>Xin Tan#</strong>, He Zhu, Wuyi Liu, Jiachen Xu, Yuan Xie, Lizhuang Ma (# corresponding author)<br />
<em>Conference on Computational Visual Media (CVM)</em>, 2024<strong></strong><br/>
<strong><em><font color="red">(YZ. J. is the third-year undergraduate student.)</font></em></strong> <br/> 
[<a href="https://link.springer.com/content/pdf/10.1007/978-981-97-2095-8_3.pdf?pdf=inline%20link">PDF </a>]
</p ></li>

<font color="red"><strong><em>2023</em><br/></strong></font> 
TPAMI*2, CVPR*4, ICCV*1, TIP*1, CVM*1, JCAD*1

<li><p><font color="[0.1,0.6,0.99]"><strong>Point Mask Transformer for Outdoor Point Cloud Semantic Segmentation</strong></font> <br />
Xiangqian Li, <strong>Xin Tan#</strong>, Zhizhong Zhang, Yuan Xie, and Lizhuang Ma (# corresponding author)<br />
<em>Computational Visual Media</em>, 2023  <strong></strong><br/> 
[<a href="">PDF (Coming soon) </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Glass Surface Detection Method Based on Visual Distortion  (in Chinese)</strong></font> <br />
<strong>Xin Tan</strong>, Fulin Qi, Nan Wang, Zhizhong Zhang, Yuan Xie, and Lizhuang Ma  <br />
<em>Journal of Computer-Aided Design & Computer Graphics</em>, 2023  <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://www.jcad.cn/cn/article/doi/10.3724/SP.J.1089.2023-00342">PDF </a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Positive-Negative Receptive Field Reasoning for Omni-supervised 3D Segmentation</strong></font> <br />
<strong>Xin Tan*</strong>, Qihang Ma*, Jingyu Gong, Jiachen Xu, Zhizhong Zhang, Haichuan Song, Yanyun Qu,
Yuan Xie, and Lizhuang Ma  <br />
<em>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023  <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
<strong><em><font color="red">(The extented version of CVPR 2021)</font></em></strong><br/> 
[<a href="https://ieeexplore.ieee.org/document/10264222">PDF </a>]
[<a href="https://github.com/NotACracker/RFCR_NL">Code </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Unveiling the Power of CLIP in Unsupervised Visible-Infrared Person Re-Identification</strong></font> <br />
Zhong Chen, Zhizhong Zhang, <strong>Xin Tan</strong>, Yanyun Qu, Yuan Xie<br />
<em>ACM MM</em>, 2023<strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://dl.acm.org/doi/abs/10.1145/3581783.3612050">PDF </a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Instance and Category Supervision are Alternate Learners for Continual Learning</strong></font> <br />
Xudong Tian, Zhizhong Zhang, <strong>Xin Tan</strong>, Jun Liu, Chengjie Wang, Yanyun Qu, Guannan Jiang, Yuan Xie<br />
<em>Proc. IEEE ICCV</em>, 2023<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Instance_and_Category_Supervision_are_Alternate_Learners_for_Continual_Learning_ICCV_2023_paper.html">PDF </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Boosting Night-time Scene Parsing with Learnable Frequency</strong></font> <br />
Zhifeng Xie, Sen Wang, Ke Xu, Zhizhong Zhang, <strong>Xin Tan#</strong>, Yuan Xie, Lizhuang Ma (# corresponding author)<br />
<em>IEEE Trans. on Image Processing (TIP)</em>, 2023<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="http://ieeexplore.ieee.org/document/10105211">PDF</a>]
[<a href="https://github.com/wangsen99/FDLNet">Code</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Boosting Semi-Supervised Learning by Exploiting All Unlabeled Data</strong></font> <br />
Yuhao Chen, <strong>Xin Tan#</strong>, Borui Zhao, Zhaowei Chen, Renjie Song, Jiajun Liang, Xuequan Lu (# corresponding author)<br />
<em>Proc. IEEE CVPR</em>, 2023<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Boosting_Semi-Supervised_Learning_by_Exploiting_All_Unlabeled_Data_CVPR_2023_paper.html">PDF</a>]
[<a href="https://github.com/megvii-research/FullMatch">Code</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Learning to Detect Mirrors from Videos via Dual Correspondences</strong></font> <br />
Jiaying Lin*, <strong>Xin Tan*</strong>, Rynson Lau (* joint first authors) <br />
<em>Proc. IEEE CVPR</em>, 2023<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Learning_To_Detect_Mirrors_From_Videos_via_Dual_Correspondences_CVPR_2023_paper.html">PDF</a>]
[<a href="https://jiaying.link/cvpr2023-vmd/">Code</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Rethinking Gradient Projection Continual Learning: Stability / Plasticity Feature Space Decoupling</strong></font> <br />
Zhen Zhao, Zhizhong Zhang, <strong>Xin Tan</strong>, Jun Liu, Yanyun Qu, Yuan Xie, Lizhuang Ma <br />
<em>Proc. IEEE CVPR</em>, 2023<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Rethinking_Gradient_Projection_Continual_Learning_Stability__Plasticity_Feature_Space_CVPR_2023_paper.html">PDF</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Multi-Centroid Task Descriptor for Dynamic Class Incremental Inference</strong></font> <br />
Tenghao Cai, Zhizhong Zhang, <strong>Xin Tan</strong>, Yanyun Qu, Guannan Jiang, Chengjie Wang, Yuan Xie <br />
<em>Proc. IEEE CVPR</em>, 2023<strong><em><font color="red"> (CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Cai_Multi-Centroid_Task_Descriptor_for_Dynamic_Class_Incremental_Inference_CVPR_2023_paper.html"> PDF </a>]
[<a href="https://github.com/CSIncWW/MultiCentroidGate"> Code </a>]
</p></li>

<li><font color="[0.1,0.6,0.99]"><strong>Scene Point Cloud Understanding and Reconstruction Technologies in 3D Space
 (in Chinese)</strong></font> <br />
Jingyu Gong, Yujin Lou, Fengqi Liu, Zhiwei Zhang, Haoming Chen, Zhizhong Zhang, <strong>Xin Tan</strong>, Yuan Xie, Lizhuang Ma <br />
<em>Journal of Image and Graphics</em>, 2023<br/>
[<a href="https://www.cjig.cn/zh/article/doi/10.11834/jig.230004/">PDF</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Mirror Detection with the Visual Chirality Cue</strong></font> <br />
<strong>Xin Tan</strong>, Jiaying Lin, Ke Xu, Pan Chen, Lizhuang Ma, and Rynson Lau <br />
<em>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023 <strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
<strong><em><font color="red">(ESI highly cited)</font></em></strong> <br/> 
[<a href="https://dmcv.sjtu.edu.cn/data/project/vcnet/vcnet_tran_final.pdf">PDF</a>]
[<a href="https://dmcv.sjtu.edu.cn/data/project/vcnet/vcnet_release.zip">Code</a>]
[<a href="https://dmcv.sjtu.edu.cn/data/project/vcnet/MSD_ours.zip">MSD Maps</a>]
[<a href="https://dmcv.sjtu.edu.cn/data/project/vcnet/pmd_ours.zip">PMD Maps</a>]
[<a href="https://dmcv.sjtu.edu.cn/data/project/vcnet/RGBD_ours.zip">RGBD-Mirror Maps</a>]
</p></li>



<font color="red"><strong><em>2022</em><br/></strong></font> 

<li><p><font color="[0.1,0.6,0.99]"><strong>Optimization over Disentangled Encoding: Unsupervised Cross-Domain Point Cloud Completion via Occlusion Factor Manipulation</strong></font> <br />
Jingyu Gong, Fengqi Liu, Jiachen Xu, Min Wang, <strong>Xin Tan</strong>, Zhizhong Zhang, Ran Yi, Haichuan Song, Yuan Xie, Lizhuang Ma <br />
<em>Proc. ECCV</em>, 2022<br/>
[<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136620504.pdf">PDF </a>]
[<a href="https://github.com/azuki-miho/OptDE"> Code </a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Survey of Expression Action Unit Recognition Based on Deep Learning
 (in Chinese)</strong></font> <br />
Zhiwen Shao, Yong Zhou, <strong>Xin Tan</strong>, Lizhuang Ma, Bin Liu, Rui Yao <br />
<em>ACTA ELECTRONICA SINICA</em>, 2022<strong><em><font color="red">(CCF-A)</font></em></strong><br/>  
[<a href="https://www.ejournal.org.cn/CN/10.12263/DZXB.20210639">PDF</a>]
</p></li>



<li><p><font color="[0.1,0.6,0.99]"><strong>Frequency-aware Camouflaged object Detection</strong></font> <br />
Jiaying Lin*, <strong>Xin Tan*</strong>, Ke Xu, Lizhuang Ma, and Rynson Lau (* joint first authors)<br />
<em>ACM Trans. on Multimedia Computing, Communications, and Applications</em>, 2022<br/>
[<a href="https://dl.acm.org/doi/10.1145/3545609">PDF</a>]
[<a href="http://jiaying.link/files/TOMM22-COD-results.zip">Results</a>]</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Rethinking Efficient Lane Detection via Curve Modeling</strong></font>   <iframe src="https://ghbtns.com/github-btn.html?user=voldemortX&amp;repo=pytorch-auto-drive&amp;type=star&amp;count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe><br />
Zhengyang Feng, Shaohua Guo, <strong>Xin Tan#</strong>, Ke Xu, Min Wang, Lizhuang Ma (# corresponding author)<br />
<em>Proc. IEEE CVPR</em>, 2022<strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Rethinking_Efficient_Lane_Detection_via_Curve_Modeling_CVPR_2022_paper.pdf">PDF</a>]
[<a href="https://github.com/voldemortX/pytorch-auto-drive">Project Page</a>]</p></li>



<li><p><font color="[0.1,0.6,0.99]"><strong>DMT: Dynamic Mutual Training for Semi-Supervised Learning</strong></font> <br />
Zhengyang Feng, Qianyu Zhou, Qiqi Gu, <strong>Xin Tan#</strong>, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma (# corresponding author)<br />
<em>Pattern Recognition</em>, 2022<br/>
[<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">PDF</a>]
[<a href="https://github.com/voldemortX/DST-CBC">Code</a>]</p></li>



<li><p><font color="[0.1,0.6,0.99]"><strong>HSNet: Hierarchical Semantics Network for Scene Parsing</strong></font> <br />
<strong>Xin Tan</strong>, Jiachen Xu, Ying Cao, Ke Xu, Lizhuang Ma, Rynson Lau<br />
<em>The Visual Computer</em>, 2022<br/>
[<a href="https://link.springer.com/content/pdf/10.1007/s00371-022-02477-3.pdf">PDF</a>]
</p></li>


<font color="red"><strong><em>2021</em><br/></strong></font> 

<li><p><font color="[0.1,0.6,0.99]"><strong>Night-time Scene Parsing with a Large Real Dataset</strong></font> <br />
<strong>Xin Tan</strong>,  Ke Xu, Ying Cao, Yiheng Zhang, Lizhuang Ma, Rynson Lau <br />
<em>IEEE Trans. on Image Processing (TIP)</em>, 2021<strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://arxiv.org/pdf/2003.06883.pdf">PDF</a>]
[<a href="https://dmcv.sjtu.edu.cn/people/phd/tanxin/NightCity/index.html">Project Page</a>]</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Semantic-aware Dehazing Network with Adaptive Feature Fusion</strong></font> <br />
Shengdong Zhang, Wenqi Ren, <strong>Xin Tan</strong>, Zhi-Jie Wang, Yong Liu, Jingang Zhang, Xiaoqin Zhang, Xiaochun Cao <br />
<em>IEEE Trans. on Cybernetics (TCyB)</em>, 2021<br/>
[<a href="https://ieeexplore.ieee.org/abstract/document/9622120">PDF</a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Confident Semantic Ranking Loss for Part Parsing</strong></font> <br />
<strong>Xin Tan</strong>, Jiachen Xu, Zhou Ye, Jinkun Hao, Lizhuang Ma <br />
<em>Proc. IEEE ICME</em>, 2021<br/>
[<a href="https://ieeexplore.ieee.org/abstract/document/9428332">PDF</a>]
[<a href="https://github.com/tanxincs/CSR">Code</a>]
</p></li>





<li><p><font color="[0.1,0.6,0.99]"><strong>Omni-supervised Point Cloud Segmentation via Gradual Receptive Field Component Reasoning</strong></font> <br />
Jingyu Gong, Jiachen Xu, <strong>Xin Tan</strong>, Haichuan Song, Yanyun Qu, Yuan Xie, Lizhuang Ma <br />
<em>Proc. IEEE CVPR</em>, 2021<strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_Omni-Supervised_Point_Cloud_Segmentation_via_Gradual_Receptive_Field_Component_Reasoning_CVPR_2021_paper.pdf">PDF</a>]
[<a href="https://github.com/azuki-miho/RFCR">Code</a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Boundary-Aware Geometric Encoding for Semantic Segmentation of Point Clouds</strong></font> <br />
Jingyu Gong, Jiachen Xu, <strong>Xin Tan</strong>, Jie Zhou, Yanyun Qu, Yuan Xie, Lizhuang Ma <br />
<em>Proc. AAAI</em>, 2021<strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/16232/16039">PDF</a>]
[<a href="https://github.com/JchenXu/BoundaryAwareGEM">Code</a>]
</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Weakly-Supervised Saliency Detection via Salient Object Subitizing</strong></font> <br />
Xiaoyang Zheng*, <strong>Xin Tan*</strong>, Jie Zhou, Lizhuang Ma, Rynson WH Lau (* joint first authors)<br />
<em>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT)</em>, 2021<br/>
[<a href="https://ieeexplore.ieee.org/abstract/document/9314082/">PDF</a>]
[<a href="https://drive.google.com/drive/folders/1wDe0efc8dUq8pbwQqfh1epgNLpMy_aRt?usp=sharing">Results</a>]
</p></li>


<font color="red"><strong><em>2020 and Before 2020</em><br/></strong></font> 



<li><p><font color="[0.1,0.6,0.99]"><strong>SceneEncoder: Scene-Aware Semantic Segmentation of Point Clouds with A Learnable Scene Descriptor</strong></font> <br />
Jiachen Xu, Jingyu Gong, Jie Zhou, <strong>Xin Tan</strong>, Yuan Xie, Lizhuang Ma <br />
<em>Proc. IJCAI</em>, 2020<strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://www.ijcai.org/Proceedings/2020/0084.pdf">PDF</a>]
[<a href="https://github.com/azuki-miho/SceneEncoder">Code</a>]
</p></li>



<li><p><font color="[0.1,0.6,0.99]"><strong>Re-ID Driven Localization Refinement for Person Search</strong></font> <br />
Chuchu Han, Jiacheng Ye, Yunshan Zhong, <strong>Xin Tan</strong>, Chi Zhang, Changxin Gao, Nong Sang <br />
<em>Proc. IEEE ICCV</em>, 2019<strong><em><font color="red">(CCF-A)</font></em></strong><br/> 
[<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Han_Re-ID_Driven_Localization_Refinement_for_Person_Search_ICCV_2019_paper.pdf">PDF</a>]
</p></li>



<li><p><font color="[0.1,0.6,0.99]"><strong>Saliency Detection by Deep Network with Boundary Refinement and Global Context</strong></font> <br />
<strong>Xin Tan</strong>, Hengliang Zhu, <a href="https://zhiwenshao.github.io/">Zhiwen Shao</a>, Xiaonan Hou, Yangyang Hao, Lizhuang Ma <br />
<em>Proc. IEEE ICME</em>, 2019<br/>
[<a href="https://ieeexplore.ieee.org/abstract/document/8486572">PDF</a>]
[<a href="https://www.dropbox.com/sh/sggqofpgpm5nf95/AAA4sxEqjFdyeXgX2hlFI6EAa?dl=0">Results (DropBox)</a>]
</p></li>





<details>
<summary><font color="red">More</font></summary>


<li><p><font color="[0.1,0.6,0.99]"><strong>A Shape-Aware Feature Extraction Module for Semantic Segmentation of 3D Point Clouds</strong></font> <br />
Jiachen Xu, Jie Zhou, <strong>Xin Tan#</strong>, Lizhuang Ma (# corresponding author)<br />
<em>Proc. ICONIP</em>, 2020<br/>
[<a href="https://link.springer.com/chapter/10.1007/978-3-030-63820-7_32">PDF</a>]
</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Single Image Deraining via Detail-guided Efficient Channel Attention Network</strong></font> <br />
Xiao Lin, Qi Huang, Wei Huang, <strong>Xin Tan#</strong>, Meie Fang, Lizhuang Ma  (# corresponding author)<br />
<em>Computers & Graphics</em>, 2021<br/>
[<a href="https://www.sciencedirect.com/science/article/abs/pii/S009784932100056X">PDF</a>]
</p></li>



<li><p><font color="[0.1,0.6,0.99]"><strong>Deep Multi-Center Learning for Face Alignment</strong></font> <br />
<a href="https://zhiwenshao.github.io/">Zhiwen Shao</a>, Hengliang Zhu, <strong>Xin Tan</strong>, Yangyang Hao, Lizhuang Ma <br />
<em>Neurocomputing</em>, 2019. <br />
[<a href="https://www.sciencedirect.com/science/article/pii/S0925231219304515">PDF</a>]
[<a href="https://github.com/ZhiwenShao/MCNet-Extension">Codes</a>]</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>MCCH: A novel convex hull prior based solution for saliency detection</strong></font> <br />
Xiao Lin, Zhi-Jie Wang, <strong>Xin Tan</strong>, Mei-E Fang, Neal N Xiong, Lizhuang Ma <br />
<em>Information Sciences</em>, Volume 485, June 2019, Pages 521-539 <br />
[<a href="https://www.sciencedirect.com/science/article/pii/S0020025519300970">PDF</a>]</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Accurate and Efficient Object Detection with Context Enhancement Block</strong></font> <br />
Yuhao Chen, Min Zhao, <strong>Xin Tan</strong>, Hong Tang, Dihua Sun <br />

<em>IEEE ICME</em> 2019. <br />
[<a href="https://ieeexplore.ieee.org/abstract/document/8784781">PDF</a>]
[<a href="https://github.com/dlyldxwl/CEBNet">Codes</a>]</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Facial Landmark Detection Under Large Pose</strong></font> <br />
Yangyang Hao, Hengliang Zhu, <a href="https://zhiwenshao.github.io/">Zhiwen Shao</a>, <strong>Xin Tan</strong>, Lizhuang Ma <br />
<em>IEEE ICONIP</em>, 2018. <br />
[<a href="https://link.springer.com/chapter/10.1007/978-3-030-04212-7_60">PDF</a>]</p></li>

 
<li><p><font color="[0.1,0.6,0.99]"><strong>Multi-Path Feature Fusion Network for Saliency Detection</strong></font> <br />
Hengliang Zhu, <strong>Xin Tan</strong>, <a href="https://zhiwenshao.github.io/">Zhiwen Shao</a>, Yangyang Hao, Lizhuang Ma <br />
<em>IEEE  ICME</em>, 2018. <br />
[<a href="https://ieeexplore.ieee.org/abstract/document/8486571">PDF</a>]</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Molecular and phenotypic spectrum of Noonan syndrome in Chinese patients</strong></font> <br />
Xin Li*, Ruen Yao*, <strong>Xin Tan*</strong>, Niu Li, Yu Ding, Juan Li, Guoying Chang, Yao Chen, Lizhuang Ma, Jian Wang, Lijun Fu, Xiumin Wang <br />
	(* joint first authors)<br />
<em>Clinical Genetics</em>, Volume 96, Issue 4, October 2019, Pages 290-299. <br />
[<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cge.13588">PDF</a>]</p></li>


<li><p><font color="[0.1,0.6,0.99]"><strong>Learning the Spiral Sharing Network with Minimum Salient Region Regression for Saliency Detection</strong></font> <br />
Zukai Chen, <strong>Xin Tan</strong>, Hengliang Zhu, Shouhong Ding, Lizhuang Ma, Haichuan Song <br />

<em>IEEE ICASSP</em>, 2019. <br />
[<a href="https://ieeexplore.ieee.org/abstract/document/8682531">PDF</a>]</p></li>

<li><p><font color="[0.1,0.6,0.99]"><strong>Object-Level Salience Detection by Progressively Enhanced Network</strong></font> <br />
Wang Yuan, Haichuan Song, <strong>Xin Tan</strong>,, Chengwei Chen, Shouhong Ding, Lizhuang Ma <br />
<em>ICANN</em>, 2019. <br />
[<a href="https://link.springer.com/chapter/10.1007/978-3-030-30508-6_30">PDF</a>]</p></li>
 
</details>


</ul>


<hr />
<h2>Awards </h2>
<strong>Research</strong>
<ul>
<li><strong>入选第十届中国科协青年人才托举工程</strong>, 2025.1</li>
<li><strong>中国图象图形学学会博士学位论文激励计划</strong>, 2024.12 </li>	
<li><strong>《中国图象图形学学报》年度优秀论文</strong>, 2024.12</li>	
<li><strong>世界互联网大会领先科技奖</strong>, 序10, 2024.11</li>
<li><strong>CCF-腾讯犀牛鸟基金优秀项目</strong>, 2024.10</li>	
<li><strong>上海市晨光人才计划</strong>, 2024.1</li>	
<li><strong>上海市扬帆人才计划</strong>, 2023.4</li>	
<li><strong>中国地理信息产业协会地理信息科技进步二等奖</strong>, 序10 2022.8</li>		
<li><strong>上海市优秀毕业生</strong>, 2022.6</li>
<li><strong>上海市科技进步特等奖</strong>, 序13, 2020.12</li>
<li><strong>上海交通大学首届十大科技进展入选项目</strong>, 序7, 2020.12 </li>
<li><strong>世界人工智能大会TOP30榜单项目</strong>, 序8, 2019.10</li>
<li><strong>重庆市优秀毕业生</strong>, 2017.6</p> </li>

</ul>
<strong>Teaching</strong>

<ul>

<li><strong>华东师范大学研究生创新实践竞赛优秀，指导教师</strong>, 2024.11</li>	
<li><strong>中国研究生人工智能创新大赛优秀，指导教师</strong>, 2024.11</li>	
<li><strong>国家级大学生创新创业训练计划优秀项目（2项），指导教师</strong>, 2024.6 </li>	
<li><strong>《数字逻辑电路》获评最受学生欢迎课程</strong>, 2024.1 </li>
<li><strong>华东师范大学研究生教育卓越育人奖（优秀研究生导师奖）</strong>, 2023.12</li>
<li><strong>中国国际“互联网+”大学生创新创业大赛铜奖，指导教师</strong>, 2023.6</li>

</ul>

<hr />

<h2>Patents</h2>

Only approved patents are displayed.

<ul>
	<li><strong>谭鑫</strong>;纪宇舟;张志忠;谢源，“一种基于特征网格映射的高效语义三维重建方法”，发明专利，已授权，ZL 2024 1 0670919.5</li>
	<li><strong>谭鑫</strong>;许嘉晨;马利庄，“一种基于层次化语义先验的语义分割方法”，发明专利， 已授权，ZL 2021 1 0629864.X</li>
	<li><strong>谭鑫</strong>;纪宇舟;谢源，“一种多尺度特征金字塔的含语义三维重建方法”，发明专利，已授权，ZL 2023 1 1448872.X</li>
	<li>陈敏刚;方鸿涛;马泽宇;王瑞云;<strong>谭鑫</strong>;沈颖;胡芸;葛建新，“一种图像分类系统对抗性样本生成方法、系统及电子设备”，发明专利，已授权，ZL 2023 1 1411509.0</li>
	
</ul>
<hr />

<h2>Education Experience</h2>


<ul>
<li><p>2017.9 - 2022.6: Joint Ph.D. Scheme (Dual Degree), CS Department, SJTU & CS Department, CityU HK
<li><p>2013.9 - 2017.6: B.Eng, School of Automation, CQU</a></br> 
2014.9 - 2017.6: B.BM, School of Economics and Business Administration, CQU</p></li>

<li><p>2010.9 - 2013.6: Chongqing Bashu Secondary School, Yuzhong District, Chongqing </a></br> 
</ul>

<hr />

<h2>Working Experience</h2>
<ul>
<li><p>2025/02&ndash;Present: Research Professor (Zijiang Young Scholar), School of Computer Science and Technology, East China Normal University</p>
<li><p>2022/07&ndash;2025.01: Associate Research Professor, School of Computer Science and Technology, East China Normal University</p>
</li>
</ul>
<hr />


<h2>Teaching Experience</h2>
<ul>
<li><p>2024 Fall, COMS0031132060.01	Signals and Systems (信号与系统), 36 hours, 2 credits </a></p>
<li><p>2024 Fall, COMS0031121015.03	Digital Logic Circuit (数字逻辑电路), 90 hours, 4 credits <strong><em><font color="red"> (The most popular course for students)</font></em></strong></a></p>
<li><p>2023 Fall, COMS0031121015.03	Digital Logic Circuit (数字逻辑电路), 90 hours, 4 credits <strong><em><font color="red"> (The most popular course for students)</font></em></strong></a></p>
<li><p>2022 Fall, COMS0031132105.01	Introduction of Deep Learning (深度学习基础与导论) with <a href="https://faculty.ecnu.edu.cn/_s16/xy2_11342/main.psp">Prof. Yuan Xie</a>, 32 hours, 2 credits</p>
</li>
</ul>
<hr />

<h2>Professional Service</h2>

<ul>
	<li>Associate Editor:
	<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">Pattern Recognition <strong>(JCR Q1, Top, CCF-B, IF: 7.5)</strong></li>
		<li style="margin: 0.1em;">Alexandria Engineering Journal <strong>(JCR Q1, Top, IF: 6.2)</strong></li>
		<li style="margin: 0.1em;">The Visual Computer <strong>(CCF-C, IF: 3.0)</strong></li>
		<li style="margin: 0.1em;">CMC-Computers, Materials & Continua <strong>(IF: 2.1)</strong></li>
	</ul>
	</li>
</ul>


<ul>
	<li>Conference reviewer/Program committee:
	<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
		<li style="margin: 0.1em;">IEEE International Conference on Computer Vision (ICCV)</li>
		<li style="margin: 0.1em;">European Conference on Computer Vision (ECCV)</li>
		<li style="margin: 0.1em;">Association for the Advancement of Artificial Intelligence (AAAI)</li>
		<li style="margin: 0.1em;">International Joint Conference on Artificial Intelligence (IJCAI)</li>
		<li style="margin: 0.1em;">International Conference on Multimedia and Expo (ICME)</li>
		<li style="margin: 0.1em;">ACM International Conference on Multimedia (ACM MM)</li>
		<li style="margin: 0.1em;">International Conference on Image and Graphics (ICIG)</li>
	</ul>
	</li>
</ul>

<ul>
	<li>Journal reviewer:
	<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
		<li style="margin: 0.1em;">International Journal of Computer Vision (IJCV)</li>
		<li style="margin: 0.1em;">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
		<li style="margin: 0.1em;">IET Computer Vision</li>
		<li style="margin: 0.1em;">IEEE Journal of Biomedical and Health Informatics (JBHI)</li> 
		<li style="margin: 0.1em;">International Journal of Digital Earth</li> 
		<li style="margin: 0.1em;">IEEE Transactions on Vehicular Technology (TVT)</li> 
		<li style="margin: 0.1em;">Machine Vision and Applications</li>
		<li style="margin: 0.1em;">Engineering Applications of Artificial Intelligence (EAAI)</li>
		
	</ul>
	</li>
	
	<li>Other Academic service:
	<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">Organization Chair, <a href="https://dmcv.sjtu.edu.cn/cadcg2023/">CCF CAD/CG 2023 (Shanghai)</a></li>
	</ul>
	<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">中国科协三维视觉与数字内容决策咨询专家团队</a></li>
	</ul>
		<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">中国计算机学会 计算机辅助设计与图形学专业委员会 执行委员，秘书</a></li>
	</ul>
	<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">中国图学学会 可视化与认知计算专业委员会 委员，秘书</a></li>
	</ul>
		<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">中国图象图形学学会 数字娱乐与智能生成专业委员会 委员</a></li>
	</ul>	<ul style="margin: 0.5em;">
		<li style="margin: 0.1em;">中国图象图形学学会 三维视觉专业委员会 委员</a></li>
	</ul>
	</li>
</ul>

</div>

<hr />



<div id="footer">
	<p><center><font face="Arial">
        <br>
            &copy; Xin Tan | Last updated: April 2025.
			<!-- hitwebcounter Code START -->
<a href="https://www.hitwebcounter.com" target="_blank">
Visitor number:
<img src="https://hitwebcounter.com/counter/counter.php?page=8093152&style=0001&nbdigits=8&type=page&initCount=0" title="Free Counter" Alt="web counter"   border="0" /></a>  
        </font>

		</center></p>
		
</div>
